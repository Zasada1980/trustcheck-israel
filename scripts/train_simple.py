"""
–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è —á–µ—Ä–µ–∑ llamafactory-cli
"""

import subprocess
import sys
import json
from pathlib import Path

LLAMAFACTORY_PATH = Path("E:/LLaMA-Factory")

# –°–æ–∑–¥–∞—Ç—å YAML –∫–æ–Ω—Ñ–∏–≥ (LLaMA Factory –∏—Å–ø–æ–ª—å–∑—É–µ—Ç YAML)
YAML_CONFIG = """### model
model_name_or_path: Qwen/Qwen2.5-1.5B-Instruct

### method
stage: sft
do_train: true
finetuning_type: lora
lora_target: all

### dataset
dataset: trustcheck_knowledge
template: qwen
cutoff_len: 4096
overwrite_cache: true
preprocessing_num_workers: 4

### output
output_dir: saves/trustcheck-ai
logging_steps: 10
save_steps: 500
plot_loss: true
overwrite_output_dir: true

### train
per_device_train_batch_size: 2
gradient_accumulation_steps: 4
learning_rate: 5.0e-5
num_train_epochs: 3.0
lr_scheduler_type: cosine
warmup_ratio: 0.1
bf16: true

### lora
lora_rank: 8
lora_alpha: 16
lora_dropout: 0.05
"""

def check_dataset():
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    dataset_path = LLAMAFACTORY_PATH / "data" / "trustcheck_knowledge_base.json"
    if not dataset_path.exists():
        print(f"‚ùå –î–∞—Ç–∞—Å–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {dataset_path}")
        return False
    
    dataset_size = dataset_path.stat().st_size / 1024 / 1024
    print(f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç: {dataset_size:.2f} MB")
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å dataset_info.json
    info_path = LLAMAFACTORY_PATH / "data" / "dataset_info.json"
    with open(info_path, 'r', encoding='utf-8') as f:
        info = json.load(f)
    
    if "trustcheck_knowledge" not in info:
        print("‚ö†Ô∏è –î–æ–±–∞–≤–ª—è—é –¥–∞—Ç–∞—Å–µ—Ç –≤ dataset_info.json...")
        info["trustcheck_knowledge"] = {
            "file_name": "trustcheck_knowledge_base.json",
            "formatting": "alpaca",
            "columns": {
                "prompt": "instruction",
                "query": "input",
                "response": "output",
                "system": "system"
            }
        }
        with open(info_path, 'w', encoding='utf-8') as f:
            json.dump(info, f, ensure_ascii=False, indent=2)
    
    print("‚úÖ –î–∞—Ç–∞—Å–µ—Ç –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω")
    return True

def train():
    """–ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ"""
    print("=" * 60)
    print("üöÄ TrustCheck AI Training")
    print("=" * 60)
    
    if not check_dataset():
        return False
    
    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å YAML –∫–æ–Ω—Ñ–∏–≥
    config_path = LLAMAFACTORY_PATH / "trustcheck_config.yaml"
    with open(config_path, 'w', encoding='utf-8') as f:
        f.write(YAML_CONFIG)
    
    print(f"\n‚úÖ –ö–æ–Ω—Ñ–∏–≥: {config_path}")
    print("\nüéØ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è (30-60 –º–∏–Ω—É—Ç)...")
    print("-" * 60)
    
    # –ó–∞–ø—É—Å—Ç–∏—Ç—å —á–µ—Ä–µ–∑ llamafactory-cli train
    cmd = [
        "llamafactory-cli", "train",
        str(config_path)
    ]
    
    try:
        result = subprocess.run(
            cmd,
            cwd=str(LLAMAFACTORY_PATH),
            check=True,
            text=True,
            capture_output=False
        )
        
        print("\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        return True
        
    except subprocess.CalledProcessError as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
        return False
    except FileNotFoundError:
        print("\n‚ùå llamafactory-cli –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print("–ü–æ–ø—Ä–æ–±—É–π: pip install llamafactory-cli")
        return False

if __name__ == "__main__":
    success = train()
    sys.exit(0 if success else 1)
